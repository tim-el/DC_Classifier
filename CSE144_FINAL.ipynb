{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 144 Fall 2023 Final Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-1: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971\n"
     ]
    }
   ],
   "source": [
    "# Step-1: Data Loading and Preprocessing\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None, train=True):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.train = train  # Flag to indicate if it's training data\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        if train:\n",
    "            # Handle train dataset with labels\n",
    "            for label_dir in os.listdir(directory):\n",
    "                label_path = os.path.join(directory, label_dir)\n",
    "                if os.path.isdir(label_path):\n",
    "                    for image_file in os.listdir(label_path):\n",
    "                        image_path = os.path.join(label_path, image_file)\n",
    "                        self.images.append(image_path)\n",
    "                        self.labels.append(int(label_dir))\n",
    "        else:\n",
    "            # Handle test dataset without labels\n",
    "            for image_file in os.listdir(directory):\n",
    "                image_path = os.path.join(directory, image_file)\n",
    "                self.images.append(image_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.train:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Assuming the train and test directories are in the same directory as the script\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),  # Add horizontal flip\n",
    "    transforms.RandomApply([transforms.Grayscale(num_output_channels=3)], p=0.2),  # Convert to grayscale with a probability of 0.2\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),  # Add color jitter\n",
    "    transforms.RandomRotation(15),  # Randomly rotate by +/- 15 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load Datasets with respective transformations\n",
    "train_data = CustomDataset(train_dir, transform=train_transforms, train=True)\n",
    "test_data = CustomDataset(test_dir, transform=test_transforms, train=False)\n",
    "\n",
    "# Load Datasets\n",
    "\n",
    "train_size = int(0.9 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "print(len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-2: Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timmy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\timmy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Step-2: Model Setup\n",
    "\n",
    "# Load a pre-trained model, for example, ResNet-50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 100)  # Assuming 100 classes from the combined datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-3: Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-3: Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.005, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-4: Training Loop & Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 4.5576, Acc: 0.0237\n",
      "Epoch 2/20, Loss: 4.1309, Acc: 0.0669\n",
      "Epoch 3/20, Loss: 3.6585, Acc: 0.1617\n",
      "Epoch 4/20, Loss: 3.3267, Acc: 0.2410\n",
      "Epoch 5/20, Loss: 3.0657, Acc: 0.3090\n",
      "Epoch 6/20, Loss: 2.8562, Acc: 0.3481\n",
      "Epoch 7/20, Loss: 2.6198, Acc: 0.3975\n",
      "Epoch 8/20, Loss: 2.5007, Acc: 0.4325\n",
      "Epoch 9/20, Loss: 2.3596, Acc: 0.4923\n",
      "Epoch 10/20, Loss: 2.2602, Acc: 0.5057\n",
      "Epoch 11/20, Loss: 2.1497, Acc: 0.5108\n",
      "Epoch 12/20, Loss: 2.0405, Acc: 0.5417\n",
      "Epoch 13/20, Loss: 2.0163, Acc: 0.5304\n",
      "Epoch 14/20, Loss: 1.8875, Acc: 0.5767\n",
      "Epoch 15/20, Loss: 1.8644, Acc: 0.6128\n",
      "Epoch 16/20, Loss: 1.7737, Acc: 0.6282\n",
      "Epoch 17/20, Loss: 1.7401, Acc: 0.6303\n",
      "Epoch 18/20, Loss: 1.6649, Acc: 0.6550\n",
      "Epoch 19/20, Loss: 1.6387, Acc: 0.6519\n",
      "Epoch 20/20, Loss: 1.5914, Acc: 0.6684\n"
     ]
    }
   ],
   "source": [
    "# Step-4: Training Loop\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # Reset the gradients\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.0673, Test Acc: 0.4444\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels.squeeze()).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / len(val_loader)\n",
    "    test_acc = correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "\n",
    "test_model(model, val_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(device)  # Move the inputs to the correct device\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Assuming 'sample_submission.csv' is in the required format\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    submission['Label'] = predictions\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "save_predictions(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse144",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
